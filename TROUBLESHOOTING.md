# Vertex AI 모델 연동 트러블슈팅 기록

이 문서는 Vertex AI 튜닝 모델을 API 서버 및 프론트엔드와 연동하는 과정에서 발생했던 주요 오류와 해결 과정을 기록합니다.

### 1. `404 Publisher Model ... not found` 오류

-   **원인:** `api_server.py`의 `TUNED_MODEL_ID`에 **튜닝된 모델의 ID**가 아닌, **기반 모델(Publisher Model)의 ID**를 잘못 입력함.
-   **해결책:** Vertex AI의 **"튜닝"** 메뉴에서 완료된 튜닝 작업의 세부 정보로 이동하여, `projects/.../models/...` 형식의 **전체 모델 리소스 이름**을 찾아 정확히 입력해야 함.

### 2. `403 ... model was not allowlisted` 오류

-   **원인:** 프로젝트가 튜닝에 사용한 기반 모델(예: `gemini-1.5-flash-002`)을 사용할 수 있도록 **사전 승인(allowlist)되지 않음.**
-   **해결책:**
    1.  **(권장)** 별도의 승인이 필요 없는 **범용(GA) 모델** (예: `gemini-1.0-pro-002`)을 사용하여 다시 튜닝.
    2.  (시간 소요) 모델 가든에서 해당 모델의 사용 권한을 별도로 요청하고 승인될 때까지 대기.

### 3. `us-central1 리전에서는 ... 모델을 사용할 수 없습니다` 오류

-   **원인:** **리전 불일치.** 모델이 튜닝된 리전과 Vertex AI Studio 또는 API 코드에서 호출하는 리전이 서로 다름.
-   **해결책:**
    *   모델을 튜닝할 때, API 서버의 `LOCATION` 설정과 **동일한 리전**을 선택하는 것이 가장 좋음.
    *   만약 다른 리전에서 튜닝했다면, `api_server.py`의 `LOCATION` 변수 값을 **모델이 실제로 있는 리전** (예: `us-central1`)으로 반드시 수정해야 함.

### 4. `400 Request contains an invalid argument` (지속적인 오류)

-   **최종 원인:** 위의 1, 2, 3번 문제가 복합적으로 작용하여 발생한 최종 오류. 특히 **리전 불일치**와 **잘못된 모델 ID**가 주된 원인이었음.
-   **해결 과정:**
    *   `GenerativeModel`과 `aiplatform.Endpoint` 클래스를 오가며 테스트했으나, 근본 원인은 클래스 사용법이 아닌 **모델 자체의 접근성(권한, 리전)** 문제였음.
    *   **최종 결론:** 튜닝된 Gemini 모델은 `GenerativeModel` 클래스를 통해 호출하는 것이 맞으며, 호출 시 **올바른 모델 ID**와 **정확한 리전**을 지정하는 것이 가장 중요함.
