AI CS 어시스턴트 개발 - 1단계 실행 계획목표: AI 모델 학습에 필요한 고품질의 데이터를 준비하고, 안전한 클라우드 개발 환경을 구축합니다.✅ Part 1: 데이터 수집 (Data Collection)AI가 학습할 원재료를 모으는 단계입니다.Action 1.1: 이메일 데이터 추출담당자: CS 담당자방법:Google 테이크아웃에 접속합니다.'내보낼 데이터 선택'에서 '메일'만 선택합니다.'모든 메일 데이터 포함됨' 옵션을 클릭하여, CS 관련 라벨(예: 문의, 답변완료, 버그리포트 등)만 선택합니다. 이렇게 하면 불필요한 데이터를 제외할 수 있습니다.내보내기를 생성하고 완료되면 .mbox 파일을 다운로드합니다.예상 결과물: inbox.mbox (또는 지정한 이름의 .mbox 파일)Action 1.2: 앱 리뷰 데이터 수집1.2.1. Google Play Console 리뷰 데이터 (CSV 다운로드)담당자: CS 담당자방법:Google Play Console에 접속하여 '리뷰' 섹션으로 이동합니다.월별 또는 분기별로 기간을 설정하고 '리뷰 내보내기' 기능을 사용하여 여러 개의 .csv 파일로 다운로드합니다. (예: reviews_2024_05.csv, reviews_2024_06.csv)예상 결과물: 여러 개의 월별/분기별 리뷰 .csv 파일들1.2.2. App Store Connect 리뷰 데이터 (API 연동)담당자: 개발자참고: App Store Connect 리뷰 데이터는 API 연동이 필요하여 이번 단계에서는 생략하고, 추후 필요시 진행합니다.✅ Part 2: 데이터 정제 및 비식별화 (Data Cleaning & De-identification)원재료를 AI가 먹기 좋게 다듬고, 개인정보를 안전하게 제거하는 단계입니다.Action 2.1: MBOX to CSV 변환담당자: 개발자방법:이전에 우리가 만들었던 파이썬 스크립트(mbox_converter.py)를 사용합니다.다운로드한 .mbox 파일을 스크립트와 같은 폴더에 넣고 실행합니다. 스크립트는 개인정보 비식별화 처리를 자동으로 수행합니다.예상 결과물: 비식별화된 이메일 데이터가 담긴 output_deidentified.csv 파일Action 2.2: 데이터 통합담당자: 개발자 (초기 스크립트 작성), CS 담당자 (데이터 관리)방법:데이터 폴더 구조화: Google Drive나 로컬 컴퓨터에 raw_data 같은 폴더를 만들고, 그 안에 email과 google_play 하위 폴더를 만듭니다.email 폴더에는 Action 2.1에서 생성된 이메일 CSV 파일을 넣습니다.google_play 폴더에는 Action 1.2.1에서 다운로드한 여러 개의 월별/분기별 리뷰 CSV 파일들을 그대로 넣습니다.통합 스크립트 실행: 개발자는 raw_data 폴더 안의 모든 CSV 파일을 읽어 하나의 데이터로 합친 뒤, 마스터 스프레드시트(또는 단일 CSV 파일)로 출력하는 파이썬 스크립트를 작성하고 실행합니다.장점: 이 방식을 사용하면, 나중에 새로운 리뷰 데이터가 추가될 때마다 스프레드시트를 수동으로 수정할 필요 없이, google_play 폴더에 새 파일을 넣고 스크립트를 다시 실행하기만 하면 되므로 관리가 매우 편리해집니다.예상 결과물: 모든 CS 데이터가 자동으로 합쳐진 마스터 스프레드시트 또는 master_data.csv 파일Action 2.3: 개인정보 비식별화 최종 검수담당자: CS 담당자방법:(매우 중요!) 스크립트가 놓쳤을 수 있는 개인정보가 있는지 통합된 스프레드시트를 반드시 수동으로 검토합니다.아래 항목들을 중점적으로 확인하고, 발견 시 [개인정보]와 같이 수정합니다.고객 실명닉네임, 계정 ID주문 번호, 결제 정보기타 개인을 식별할 수 있는 모든 정보예상 결과물: 개인정보가 완벽히 제거된 안전한 데이터셋✅ Part 3: 학습 데이터셋 최종 구축 (Finalizing Training Dataset)AI가 이해할 수 있는 '질문과 답변' 형식으로 데이터를 최종 가공하는 단계입니다.Action 3.1: 'prompt' / 'completion' 포맷 변환담당자: 개발자방법:마스터 스프레드시트에 prompt와 completion이라는 두 개의 새로운 열을 만듭니다.prompt 열: 단순 문의 내용만 넣는 대신, AI에게 더 풍부한 맥락을 제공하기 위해 아래와 같이 구조화된 형식으로 정보를 입력합니다. 이메일 데이터에는 날짜 정보가 포함되어 있으므로 이를 활용합니다.[문의 정보]
- 문의 일시: {이메일 수신 날짜 및 시간}
- 문의 채널: {gmail 또는 playstore}

[고객 문의 내용]
{고객의 실제 문의/리뷰 내용}
completion 열: 해당 문의에 대한 우리 담당자의 최종 답변 내용을 그대로 복사해서 붙여넣습니다.예상 결과물: 문의 날짜와 채널 정보가 포함된, 구조화된 prompt와 그에 맞는 completion으로 구성된 학습용 데이터Action 3.2: 품질 검수 및 최종 파일 저장담당자: CS 담당자방법:prompt와 completion 쌍을 검토하며, 품질이 낮은 데이터를 삭제합니다. (예: 단답형 답변, 스팸, 문의와 관련 없는 답변 등)최소 100쌍 이상의 고품질 데이터를 확보하는 것을 목표로 합니다.최종 완성된 데이터를 training_data.csv와 같은 이름의 CSV 파일로 저장합니다.예상 결과물: 최종 AI 학습 파일 training_data.csv✅ Part 4: 클라우드 인프라 설정 (Cloud Infrastructure Setup)AI를 개발하고 운영할 우리 회사만의 안전한 공간을 만드는 단계입니다.Action 4.1: Google Cloud Platform(GCP) 프로젝트 생성담당자: 개발자방법:Google Cloud Console에 접속합니다.새 프로젝트를 생성합니다. (예: banjihagames-cs-ai)결제 계정을 연결합니다. (실제 비용은 Phase 2에서 발생합니다.)예상 결과물: 회사 소유의 GCP 프로젝트Action 4.2: API 서비스 활성화담당자: 개발자방법:생성된 프로젝트의 'API 및 서비스' 대시보드로 이동합니다.Vertex AI API를 검색하여 '사용 설정'합니다.Cloud Storage API를 검색하여 '사용 설정'합니다.예상 결과물: Vertex AI와 Cloud Storage 사용 준비 완료Action 4.3: Cloud Storage 버킷 생성담당자: 개발자방법:Cloud Storage 메뉴로 이동하여 '버킷 만들기'를 클릭합니다.고유한 이름(예: banjihagames-cs-ai-data)을 지정하고, 리전은 asia-northeast3 (서울)으로 설정한 뒤 버킷을 생성합니다.생성된 버킷에 Action 3.2에서 만든 최종 학습 파일(training_data.csv)을 업로드합니다.예상 결과물: 학습 데이터를 안전하게 보관할 온라인 저장소 확보1단계 완료!위의 모든 단계를 마치면, 우리는 Phase 2에서 AI 모델을 본격적으로 학습시킬 모든 준비를 완료하게 됩니다.